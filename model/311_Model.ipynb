{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import geog\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consts\n",
    "datapath = '../rawdata/sensors/'\n",
    "metadata_file = datapath + 'nodes.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading 311\n",
    "noiseComplaints = pd.read_pickle('../data/311/311.pkl')\n",
    "noiseComplaints = gpd.GeoDataFrame(noiseComplaints, crs={'init' : 'epsg:4326'}, geometry='geometry')\n",
    "noiseComplaints = noiseComplaints['2018-01-01':'2018-12-31']\n",
    "\n",
    "## Loading taxi regions\n",
    "taxi_regions = gpd.read_file('zip://../assets/taxi_zones.zip')\n",
    "taxi_regions = taxi_regions.to_crs({'init':'epsg:3857'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorID:  sonycnode-b827eb0d8af7.sonyc\n",
      "sensorID:  sonycnode-b827eb0fedda.sonyc\n",
      "sensorID:  sonycnode-b827eb122f0f.sonyc\n",
      "sensorID:  sonycnode-b827eb132382.sonyc\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "f = open(metadata_file)\n",
    "for line in f:\n",
    "    \n",
    "    # reading sensor metadata\n",
    "    s, lat, lon = line.split(' ')\n",
    "    lat = float(lat)\n",
    "    lon = float(lon)\n",
    "    \n",
    "    print('sensorID: ', s)\n",
    "    \n",
    "    # creating empty timeseries\n",
    "    df_timeseries = pd.DataFrame()\n",
    "    df_timeseries['datetime'] = pd.date_range('2018-01-01', '2018-12-31', freq=\"1h\")\n",
    "    df_timeseries.set_index(['datetime'], inplace = True)\n",
    "    \n",
    "    # reading sensor data\n",
    "    sensorData = pd.read_pickle(datapath + s + '.pkl')\n",
    "    sensorData['dbas'] = sensorData['sum'] / sensorData['count']\n",
    "    \n",
    "    # filtering noise complaints\n",
    "    noiseComplaints_temp = noiseComplaints.to_crs({'init':'epsg:3857'})\n",
    "    noiseComplaints_temp = spatialJoin(lat, lon, s, noiseComplaints_temp)            \n",
    "    noiseComplaints_temp = noiseComplaints_temp.resample('H').agg({'Descriptor': 'count'})\n",
    "    noiseComplaints_temp.rename({'Descriptor':'noise'}, inplace=True)\n",
    "    \n",
    "    ## adding noise and dbas to the dataframe\n",
    "    df_timeseries['noise'] = noiseComplaints_temp\n",
    "    df_timeseries['dbas'] = sensorData[['dbas']]\n",
    "    \n",
    "    # adding cos and sin to the dataframe\n",
    "    df_timeseries['hour'] = df_timeseries.index.hour\n",
    "    df_timeseries['hour_sin'] = np.sin(df_timeseries['hour'])\n",
    "    df_timeseries['hour_cos'] = np.cos(df_timeseries['hour'])\n",
    "    \n",
    "    ## adding to the dictionary\n",
    "    dataset[s] = {}\n",
    "    df_timeseries = df_timeseries.dropna(subset=['dbas'])\n",
    "    df_timeseries['noise'].fillna(0, inplace=True)\n",
    "    dataset[s]['training'] = df_timeseries.dropna(subset=['dbas'])\n",
    "    \n",
    "    count += 1\n",
    "    if count > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jlrulff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/jlrulff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for sensor in dataset:\n",
    "    \n",
    "    errorDF = pd.DataFrame(columns=['actual', 'predicted', 'error', 'std_dev'])\n",
    "    \n",
    "    ## defining kernel\n",
    "    kernel_regressor = DotProduct() + WhiteKernel()\n",
    "\n",
    "    ## defining regressor\n",
    "    gp_regressor = GaussianProcessRegressor(kernel=kernel_regressor,random_state=0)\n",
    "\n",
    "    ## spliting into features and results\n",
    "    X = dataset[sensor]['training'][['noise', 'hour_sin', 'hour_cos']]\n",
    "    y = dataset[sensor]['training'][['dbas']]\n",
    "    \n",
    "    ## splitting into train test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "    ## training\n",
    "    gp_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    ## predicting\n",
    "    y_pred, y_pred_std = gp_regressor.predict(X_test, return_std=True)\n",
    "    \n",
    "    y_test['predicted'] = y_pred\n",
    "    y_test['std_dev'] = y_pred_std\n",
    "    \n",
    "    dataset[sensor]['summary'] = y_test\n",
    "    dataset[sensor]['regressor'] = gp_regressor\n",
    "    \n",
    "    count += 1\n",
    "    if count == 3:\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dbas</th>\n",
       "      <th>predicted</th>\n",
       "      <th>std_dev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-10 09:00:00</th>\n",
       "      <td>60.615308</td>\n",
       "      <td>60.609428</td>\n",
       "      <td>3.266772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 10:00:00</th>\n",
       "      <td>61.988773</td>\n",
       "      <td>60.704265</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 11:00:00</th>\n",
       "      <td>63.308503</td>\n",
       "      <td>60.933654</td>\n",
       "      <td>3.266863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 12:00:00</th>\n",
       "      <td>62.333893</td>\n",
       "      <td>61.086696</td>\n",
       "      <td>3.266862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 13:00:00</th>\n",
       "      <td>61.918141</td>\n",
       "      <td>61.022685</td>\n",
       "      <td>3.266777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 14:00:00</th>\n",
       "      <td>61.105473</td>\n",
       "      <td>60.800472</td>\n",
       "      <td>3.266770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 15:00:00</th>\n",
       "      <td>62.536082</td>\n",
       "      <td>60.624359</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 16:00:00</th>\n",
       "      <td>61.154948</td>\n",
       "      <td>60.656263</td>\n",
       "      <td>3.266766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 17:00:00</th>\n",
       "      <td>62.902482</td>\n",
       "      <td>60.866852</td>\n",
       "      <td>3.266839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 18:00:00</th>\n",
       "      <td>61.795634</td>\n",
       "      <td>61.062511</td>\n",
       "      <td>3.266878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 19:00:00</th>\n",
       "      <td>62.530282</td>\n",
       "      <td>61.063352</td>\n",
       "      <td>3.266798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 20:00:00</th>\n",
       "      <td>62.905933</td>\n",
       "      <td>60.868602</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 21:00:00</th>\n",
       "      <td>60.809826</td>\n",
       "      <td>60.275467</td>\n",
       "      <td>3.267014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 22:00:00</th>\n",
       "      <td>60.067687</td>\n",
       "      <td>60.623743</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10 23:00:00</th>\n",
       "      <td>61.852377</td>\n",
       "      <td>60.798757</td>\n",
       "      <td>3.266812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 00:00:00</th>\n",
       "      <td>57.898177</td>\n",
       "      <td>60.696372</td>\n",
       "      <td>3.267121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 01:00:00</th>\n",
       "      <td>57.823918</td>\n",
       "      <td>60.904559</td>\n",
       "      <td>3.266762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 02:00:00</th>\n",
       "      <td>61.436814</td>\n",
       "      <td>60.681303</td>\n",
       "      <td>3.266782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 03:00:00</th>\n",
       "      <td>63.018754</td>\n",
       "      <td>60.613710</td>\n",
       "      <td>3.266766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 04:00:00</th>\n",
       "      <td>57.809179</td>\n",
       "      <td>60.763924</td>\n",
       "      <td>3.266799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 05:00:00</th>\n",
       "      <td>57.075929</td>\n",
       "      <td>60.993841</td>\n",
       "      <td>3.266878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 06:00:00</th>\n",
       "      <td>58.487145</td>\n",
       "      <td>61.092074</td>\n",
       "      <td>3.266838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 07:00:00</th>\n",
       "      <td>58.842591</td>\n",
       "      <td>60.968310</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 08:00:00</th>\n",
       "      <td>66.585423</td>\n",
       "      <td>60.736336</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 09:00:00</th>\n",
       "      <td>60.260499</td>\n",
       "      <td>59.845736</td>\n",
       "      <td>3.268401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 10:00:00</th>\n",
       "      <td>60.134573</td>\n",
       "      <td>60.704265</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 11:00:00</th>\n",
       "      <td>60.407951</td>\n",
       "      <td>60.933654</td>\n",
       "      <td>3.266863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 12:00:00</th>\n",
       "      <td>60.651505</td>\n",
       "      <td>61.086696</td>\n",
       "      <td>3.266862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 13:00:00</th>\n",
       "      <td>62.940265</td>\n",
       "      <td>61.022685</td>\n",
       "      <td>3.266777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11 14:00:00</th>\n",
       "      <td>61.269037</td>\n",
       "      <td>60.800472</td>\n",
       "      <td>3.266770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 05:00:00</th>\n",
       "      <td>56.582617</td>\n",
       "      <td>60.993841</td>\n",
       "      <td>3.266878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 06:00:00</th>\n",
       "      <td>57.840272</td>\n",
       "      <td>61.092074</td>\n",
       "      <td>3.266838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 07:00:00</th>\n",
       "      <td>62.894214</td>\n",
       "      <td>60.968310</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 08:00:00</th>\n",
       "      <td>62.512556</td>\n",
       "      <td>60.736336</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 09:00:00</th>\n",
       "      <td>62.936536</td>\n",
       "      <td>60.227582</td>\n",
       "      <td>3.267005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 10:00:00</th>\n",
       "      <td>62.396495</td>\n",
       "      <td>60.704265</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 11:00:00</th>\n",
       "      <td>61.698641</td>\n",
       "      <td>60.933654</td>\n",
       "      <td>3.266863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 12:00:00</th>\n",
       "      <td>61.575472</td>\n",
       "      <td>61.086696</td>\n",
       "      <td>3.266862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 13:00:00</th>\n",
       "      <td>60.146037</td>\n",
       "      <td>61.022685</td>\n",
       "      <td>3.266777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 14:00:00</th>\n",
       "      <td>60.238061</td>\n",
       "      <td>60.800472</td>\n",
       "      <td>3.266770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 15:00:00</th>\n",
       "      <td>61.758242</td>\n",
       "      <td>60.624359</td>\n",
       "      <td>3.266778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 16:00:00</th>\n",
       "      <td>63.065677</td>\n",
       "      <td>60.656263</td>\n",
       "      <td>3.266766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 17:00:00</th>\n",
       "      <td>65.997577</td>\n",
       "      <td>60.866852</td>\n",
       "      <td>3.266839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 18:00:00</th>\n",
       "      <td>65.482756</td>\n",
       "      <td>61.062511</td>\n",
       "      <td>3.266878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 19:00:00</th>\n",
       "      <td>62.325594</td>\n",
       "      <td>61.063352</td>\n",
       "      <td>3.266798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 20:00:00</th>\n",
       "      <td>62.403420</td>\n",
       "      <td>60.868602</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 21:00:00</th>\n",
       "      <td>62.473673</td>\n",
       "      <td>60.275467</td>\n",
       "      <td>3.267014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 22:00:00</th>\n",
       "      <td>60.727860</td>\n",
       "      <td>59.860052</td>\n",
       "      <td>3.268414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-09 23:00:00</th>\n",
       "      <td>61.301672</td>\n",
       "      <td>60.416911</td>\n",
       "      <td>3.267097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 00:00:00</th>\n",
       "      <td>59.952253</td>\n",
       "      <td>61.078218</td>\n",
       "      <td>3.266811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 01:00:00</th>\n",
       "      <td>59.624492</td>\n",
       "      <td>60.904559</td>\n",
       "      <td>3.266762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 02:00:00</th>\n",
       "      <td>58.256327</td>\n",
       "      <td>60.681303</td>\n",
       "      <td>3.266782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 03:00:00</th>\n",
       "      <td>57.887009</td>\n",
       "      <td>60.613710</td>\n",
       "      <td>3.266766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 04:00:00</th>\n",
       "      <td>57.370330</td>\n",
       "      <td>60.763924</td>\n",
       "      <td>3.266799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 05:00:00</th>\n",
       "      <td>58.720829</td>\n",
       "      <td>60.993841</td>\n",
       "      <td>3.266878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 06:00:00</th>\n",
       "      <td>60.715429</td>\n",
       "      <td>61.092074</td>\n",
       "      <td>3.266838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 07:00:00</th>\n",
       "      <td>59.518464</td>\n",
       "      <td>60.968310</td>\n",
       "      <td>3.266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 08:00:00</th>\n",
       "      <td>64.300622</td>\n",
       "      <td>60.354490</td>\n",
       "      <td>3.267018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 09:00:00</th>\n",
       "      <td>65.877405</td>\n",
       "      <td>60.609428</td>\n",
       "      <td>3.266772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-10 10:00:00</th>\n",
       "      <td>64.845305</td>\n",
       "      <td>60.322419</td>\n",
       "      <td>3.267044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          dbas  predicted   std_dev\n",
       "datetime                                           \n",
       "2018-08-10 09:00:00  60.615308  60.609428  3.266772\n",
       "2018-08-10 10:00:00  61.988773  60.704265  3.266778\n",
       "2018-08-10 11:00:00  63.308503  60.933654  3.266863\n",
       "2018-08-10 12:00:00  62.333893  61.086696  3.266862\n",
       "2018-08-10 13:00:00  61.918141  61.022685  3.266777\n",
       "2018-08-10 14:00:00  61.105473  60.800472  3.266770\n",
       "2018-08-10 15:00:00  62.536082  60.624359  3.266778\n",
       "2018-08-10 16:00:00  61.154948  60.656263  3.266766\n",
       "2018-08-10 17:00:00  62.902482  60.866852  3.266839\n",
       "2018-08-10 18:00:00  61.795634  61.062511  3.266878\n",
       "2018-08-10 19:00:00  62.530282  61.063352  3.266798\n",
       "2018-08-10 20:00:00  62.905933  60.868602  3.266764\n",
       "2018-08-10 21:00:00  60.809826  60.275467  3.267014\n",
       "2018-08-10 22:00:00  60.067687  60.623743  3.266764\n",
       "2018-08-10 23:00:00  61.852377  60.798757  3.266812\n",
       "2018-08-11 00:00:00  57.898177  60.696372  3.267121\n",
       "2018-08-11 01:00:00  57.823918  60.904559  3.266762\n",
       "2018-08-11 02:00:00  61.436814  60.681303  3.266782\n",
       "2018-08-11 03:00:00  63.018754  60.613710  3.266766\n",
       "2018-08-11 04:00:00  57.809179  60.763924  3.266799\n",
       "2018-08-11 05:00:00  57.075929  60.993841  3.266878\n",
       "2018-08-11 06:00:00  58.487145  61.092074  3.266838\n",
       "2018-08-11 07:00:00  58.842591  60.968310  3.266764\n",
       "2018-08-11 08:00:00  66.585423  60.736336  3.266778\n",
       "2018-08-11 09:00:00  60.260499  59.845736  3.268401\n",
       "2018-08-11 10:00:00  60.134573  60.704265  3.266778\n",
       "2018-08-11 11:00:00  60.407951  60.933654  3.266863\n",
       "2018-08-11 12:00:00  60.651505  61.086696  3.266862\n",
       "2018-08-11 13:00:00  62.940265  61.022685  3.266777\n",
       "2018-08-11 14:00:00  61.269037  60.800472  3.266770\n",
       "...                        ...        ...       ...\n",
       "2018-11-09 05:00:00  56.582617  60.993841  3.266878\n",
       "2018-11-09 06:00:00  57.840272  61.092074  3.266838\n",
       "2018-11-09 07:00:00  62.894214  60.968310  3.266764\n",
       "2018-11-09 08:00:00  62.512556  60.736336  3.266778\n",
       "2018-11-09 09:00:00  62.936536  60.227582  3.267005\n",
       "2018-11-09 10:00:00  62.396495  60.704265  3.266778\n",
       "2018-11-09 11:00:00  61.698641  60.933654  3.266863\n",
       "2018-11-09 12:00:00  61.575472  61.086696  3.266862\n",
       "2018-11-09 13:00:00  60.146037  61.022685  3.266777\n",
       "2018-11-09 14:00:00  60.238061  60.800472  3.266770\n",
       "2018-11-09 15:00:00  61.758242  60.624359  3.266778\n",
       "2018-11-09 16:00:00  63.065677  60.656263  3.266766\n",
       "2018-11-09 17:00:00  65.997577  60.866852  3.266839\n",
       "2018-11-09 18:00:00  65.482756  61.062511  3.266878\n",
       "2018-11-09 19:00:00  62.325594  61.063352  3.266798\n",
       "2018-11-09 20:00:00  62.403420  60.868602  3.266764\n",
       "2018-11-09 21:00:00  62.473673  60.275467  3.267014\n",
       "2018-11-09 22:00:00  60.727860  59.860052  3.268414\n",
       "2018-11-09 23:00:00  61.301672  60.416911  3.267097\n",
       "2018-11-10 00:00:00  59.952253  61.078218  3.266811\n",
       "2018-11-10 01:00:00  59.624492  60.904559  3.266762\n",
       "2018-11-10 02:00:00  58.256327  60.681303  3.266782\n",
       "2018-11-10 03:00:00  57.887009  60.613710  3.266766\n",
       "2018-11-10 04:00:00  57.370330  60.763924  3.266799\n",
       "2018-11-10 05:00:00  58.720829  60.993841  3.266878\n",
       "2018-11-10 06:00:00  60.715429  61.092074  3.266838\n",
       "2018-11-10 07:00:00  59.518464  60.968310  3.266764\n",
       "2018-11-10 08:00:00  64.300622  60.354490  3.267018\n",
       "2018-11-10 09:00:00  65.877405  60.609428  3.266772\n",
       "2018-11-10 10:00:00  64.845305  60.322419  3.267044\n",
       "\n",
       "[2210 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['sonycnode-b827eb0fedda.sonyc']['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d1473016f0be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoiseComplaints_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoiseComplaints_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "summaryDF_errorMap = pd.DataFrame()\n",
    "\n",
    "regions = taxi_regions[taxi_regions['borough'] == 'Manhattan']['LocationID'].values\n",
    "regressor = dataset['sonycnode-b827eb0d8af7.sonyc']['regressor']\n",
    "\n",
    "for region in regions:\n",
    "    \n",
    "    currentDF = pd.DataFrame()\n",
    "    \n",
    "    currentRegion = taxi_regions[taxi_regions['LocationID'] == region]\n",
    "#     foliumMap = folium.Map(location=[40.742, -73.956], zoom_start=12, tiles=\"cartodbpositron\")\n",
    "#     folium.GeoJson(currentRegion).add_to(foliumMap)\n",
    "#     display(foliumMap)\n",
    "    \n",
    "    \n",
    "    ## getting all noise complaints in the given region\n",
    "    noiseComplaints_temp = noiseComplaints.to_crs({'init':'epsg:3857'})\n",
    "    noiseComplaints_temp = gpd.tools.sjoin(noiseComplaints_temp, currentRegion, how='inner', op=\"within\")\n",
    "    noiseComplaints_temp = noiseComplaints_temp.resample('H').agg({'Descriptor': 'count'})\n",
    "    noiseComplaints_temp = noiseComplaints_temp.rename({'Descriptor':'noise'}, inplace=True)\n",
    "    \n",
    "    ## adding noise to a single df\n",
    "#     currentDF = noiseComplaints_temp\n",
    "    \n",
    "    # adding cos and sin to the dataframe\n",
    "#     currentDF['hour'] = currentDF.index.hour\n",
    "#     currentDF['hour_sin'] = np.sin(currentDF['hour'])\n",
    "#     currentDF['hour_cos'] = np.cos(currentDF['hour'])\n",
    "    \n",
    "    ## predicting\n",
    "#     y_pred, y_std = regressor.predict(currentDF[['']])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    print(noiseComplaints_temp.shape)\n",
    "    print(noiseComplaints_temp.head())\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatialJoin_polygon(noiseDF, geometry, locationID, sensorID):\n",
    "    \n",
    "    sinpoly = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "    sinpoly = sinpoly.append({'geometry': geometry, 'sensorID':sensorID}, ignore_index=True) \n",
    "    sinpoly = sinpoly.to_crs({'init':'epsg:3857'})\n",
    "    \n",
    "    \n",
    "    plotPolygon(testing_map, sinpoly)\n",
    "    \n",
    "#     dataframe = gpd.tools.sjoin(noiseDF, sinpoly, how='inner', op=\"within\")\n",
    "    \n",
    "#     return dataframe\n",
    "\n",
    "def spatialJoin(sensorLat, sensorLon, sensorID, geoDataFrame):\n",
    "    \n",
    "    d = 500 # meters\n",
    "    n_points = 20\n",
    "    angles = np.linspace(0, 360, n_points)\n",
    "    center = shapely.geometry.Point(sensorLon, sensorLat)\n",
    "    polygon = Polygon(geog.propagate(center, angles, d))\n",
    "    \n",
    "    sinpoly = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "    sinpoly = sinpoly.append({'geometry': polygon, 'sensorID':sensorID}, ignore_index=True) \n",
    "    sinpoly = sinpoly.to_crs({'init':'epsg:3857'})\n",
    "    \n",
    "    dataframe = gpd.tools.sjoin(geoDataFrame, sinpoly, how='inner', op=\"within\")\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPolygon(foliumMap, polygondf):\n",
    "    folium.GeoJson(polygondf).add_to(foliumMap)\n",
    "    display(foliumMap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
