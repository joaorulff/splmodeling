{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import geog\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consts\n",
    "datapath = '../rawdata/sensors/'\n",
    "metadata_file = datapath + 'nodes.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading 311\n",
    "noiseComplaints = pd.read_pickle('../data/311/311.pkl')\n",
    "noiseComplaints = gpd.GeoDataFrame(noiseComplaints, crs={'init' : 'epsg:4326'}, geometry='geometry')\n",
    "noiseComplaints = noiseComplaints['2018-01-01':'2018-12-31']\n",
    "\n",
    "## Loading taxi regions\n",
    "taxi_regions = gpd.read_file('zip://../assets/taxi_zones.zip')\n",
    "taxi_regions = taxi_regions.to_crs({'init':'epsg:3857'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensorID:  sonycnode-b827eb0d8af7.sonyc\n",
      "sensorID:  sonycnode-b827eb0fedda.sonyc\n",
      "sensorID:  sonycnode-b827eb122f0f.sonyc\n",
      "sensorID:  sonycnode-b827eb132382.sonyc\n"
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "f = open(metadata_file)\n",
    "for line in f:\n",
    "    \n",
    "    # reading sensor metadata\n",
    "    s, lat, lon = line.split(' ')\n",
    "    lat = float(lat)\n",
    "    lon = float(lon)\n",
    "    \n",
    "    print('sensorID: ', s)\n",
    "    \n",
    "    # creating empty timeseries\n",
    "    df_timeseries = pd.DataFrame()\n",
    "    df_timeseries['datetime'] = pd.date_range('2018-01-01', '2018-12-31', freq=\"1h\")\n",
    "    df_timeseries.set_index(['datetime'], inplace = True)\n",
    "    \n",
    "    # reading sensor data\n",
    "    sensorData = pd.read_pickle(datapath + s + '.pkl')\n",
    "    sensorData['dbas'] = sensorData['sum'] / sensorData['count']\n",
    "    \n",
    "    # filtering noise complaints\n",
    "    noiseComplaints_temp = noiseComplaints.to_crs({'init':'epsg:3857'})\n",
    "    noiseComplaints_temp = spatialJoin(lat, lon, s, noiseComplaints_temp)            \n",
    "    noiseComplaints_temp = noiseComplaints_temp.resample('H').agg({'Descriptor': 'count'})\n",
    "    noiseComplaints_temp.rename({'Descriptor':'noise'}, inplace=True)\n",
    "    \n",
    "    ## adding noise and dbas to the dataframe\n",
    "    df_timeseries['noise'] = noiseComplaints_temp\n",
    "    df_timeseries['dbas'] = sensorData[['dbas']]\n",
    "    \n",
    "    # adding cos and sin to the dataframe\n",
    "    df_timeseries['hour'] = df_timeseries.index.hour\n",
    "    df_timeseries['hour_sin'] = np.sin(df_timeseries['hour'])\n",
    "    df_timeseries['hour_cos'] = np.cos(df_timeseries['hour'])\n",
    "    \n",
    "    ## adding to the dictionary\n",
    "    dataset[s] = {}\n",
    "    df_timeseries = df_timeseries.dropna(subset=['dbas'])\n",
    "    df_timeseries['noise'].fillna(0, inplace=True)\n",
    "    dataset[s]['training'] = df_timeseries.dropna(subset=['dbas'])\n",
    "    \n",
    "    count += 1\n",
    "    if count > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise</th>\n",
       "      <th>dbas</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>83.139089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>82.451193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.841471</td>\n",
       "      <td>0.540302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>82.132457</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>-0.416147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.757893</td>\n",
       "      <td>3</td>\n",
       "      <td>0.141120</td>\n",
       "      <td>-0.989992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.138646</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.756802</td>\n",
       "      <td>-0.653644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 05:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.648088</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.958924</td>\n",
       "      <td>0.283662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 06:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>76.872214</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.279415</td>\n",
       "      <td>0.960170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     noise       dbas  hour  hour_sin  hour_cos\n",
       "datetime                                                       \n",
       "2018-01-01 00:00:00    NaN  83.139089     0  0.000000  1.000000\n",
       "2018-01-01 01:00:00    NaN  82.451193     1  0.841471  0.540302\n",
       "2018-01-01 02:00:00    NaN  82.132457     2  0.909297 -0.416147\n",
       "2018-01-01 03:00:00    NaN  80.757893     3  0.141120 -0.989992\n",
       "2018-01-01 04:00:00    NaN  80.138646     4 -0.756802 -0.653644\n",
       "2018-01-01 05:00:00    NaN  76.648088     5 -0.958924  0.283662\n",
       "2018-01-01 06:00:00    NaN  76.872214     6 -0.279415  0.960170"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset['sonycnode-b827eb132382.sonyc']['training'].dropna(subset=['dbas'])\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlrulff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jlrulff/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for sensor in dataset:\n",
    "    \n",
    "    errorDF = pd.DataFrame(columns=['actual', 'predicted', 'error', 'std_dev'])\n",
    "    \n",
    "    ## defining kernel\n",
    "    kernel_regressor = DotProduct() + WhiteKernel()\n",
    "\n",
    "    ## defining regressor\n",
    "    gp_regressor = GaussianProcessRegressor(kernel=kernel_regressor,random_state=0)\n",
    "\n",
    "    ## spliting into features and results\n",
    "    X = dataset[sensor]['training'][['noise', 'hour_sin', 'hour_cos']]\n",
    "    y = dataset[sensor]['training'][['dbas']]\n",
    "    \n",
    "    ## splitting into train test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "    ## training\n",
    "    gp_regressor.fit(X_train, y_train)\n",
    "    \n",
    "    ## predicting\n",
    "    y_pred, y_pred_std = gp_regressor.predict(X_test, return_std=True)\n",
    "    \n",
    "    y_test['predicted'] = y_pred\n",
    "    y_test['std_dev'] = y_pred_std\n",
    "    \n",
    "    dataset[sensor]['summary'] = y_test\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Geospatial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def spatialJoin(sensorLat, sensorLon, sensorID, geoDataFrame):\n",
    "    \n",
    "    d = 500 # meters\n",
    "    n_points = 20\n",
    "    angles = np.linspace(0, 360, n_points)\n",
    "    center = shapely.geometry.Point(sensorLon, sensorLat)\n",
    "    polygon = Polygon(geog.propagate(center, angles, d))\n",
    "    \n",
    "    sinpoly = gpd.GeoDataFrame(crs={'init': 'epsg:4326'})\n",
    "    sinpoly = sinpoly.append({'geometry': polygon, 'sensorID':sensorID}, ignore_index=True) \n",
    "    sinpoly = sinpoly.to_crs({'init':'epsg:3857'})\n",
    "    \n",
    "    dataframe = gpd.tools.sjoin(geoDataFrame, sinpoly, how='inner', op=\"within\")\n",
    "        \n",
    "    return dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
